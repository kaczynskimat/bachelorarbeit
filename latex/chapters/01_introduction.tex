\chapter{Introduction}


In the era where \ac{IoT} continuously gathers importance~\cite{reviewIoT}, the collection of high-frequency data from smart meters offers unprecedented opportunities for operational efficiency~\cite{SmartMetersApplications}. Smart meters are a fundamental component of demand response systems, supplying them with the consumption data that is needed to operate effectively. These systems leverage this data to detect changes in the energy usage in response to electricity price fluctuations or incentive payments, which are designed to encourage lower electricity use at times of high wholesale market prices~\cite{DemandResponseSurvey}. This knowledge can be used by the energy provider to balance the energy production levels, ultimately improving the system efficiency~\cite{DemandResponseBenefits}.


However, the collection of such detailed consumption data from smart meters poses significant privacy risks. Smart meter reading can reveal sensitive characteristics about marital status, employment status, income, or the number of residents~\cite{RevealingHouseholdCharacteristicsSM}. Moreover, behavioral patterns, including residents' presence, sleep schedule, or meal times, can be inferred from this consumption data. When combined with information about specific appliances, this information may be exploited by adversaries for malicious purposes~\cite{InferringPersonalInformationFromDRS}.

Consequently, protecting this sensitive information is not merely a technical necessity for user safety, but a strict legal requirement. Within the European Union, the General Data Protection Regulation (GDPR), enacted in 2018, establishes strict rules for processing, storing, managing personal data from individuals. Its primary goal is to give individuals more responsibility over their own data and ensure that companies handle data responsibly~\cite{GDPR}.

A naive approach might suggest removing user's private information in the published data to avoid those threats. Yet, it is well-established that simply removing direct identifiers is insufficient for protecting user privacy. Infamous real-world examples, such as the de-anonymization of the Netflix Prize dataset, and foundational academic research have proven that individuals can be easily re-identified by linking seemingly innocuous data points known as quasi-identifiers~\cite{NetflixPaper}.

To counter this threat, formal privacy models like k-anonymity were developed for static datasets~\cite{Sweeney_kanon}. However, these traditional models are often too computationally intensive for the real-time, zero-delay requirements of modern data streams. This has led to the development of stream-specific algorithms, such as z-anonymity, which are designed to provide lightweight, continuous privacy protection~\cite{zanonDataStreams}.

While z-anonymity provides the core privacy, we argue that its effectiveness and the resulting data utility can be significantly influenced by data preprocessing techniques. These steps, applied before the main anonymization algorithm, can modify the data to influence the privacy-utility trade-off. For instance, generalization could possibly increase the amount of data that is ultimately published, while aggregation could drastically reduce communication overhead and system load.

The availability of these powerful tools raises a critical, underexplored architectural question: at which layer of the architecture should privacy-preserving preprocessing steps be deployed? The conventional Centralized model requires placing a high degree of trust in the central entity that collects all raw, sensitive data~\cite{dezent2025}. However, modern \ac{IoT} networks are multi-layered~\cite{reviewIoT}, consisting of smart meters, gateways, and a central entity. This motivates our investigation into how shifting preprocessing steps, such as prefiltering, generalizing, and aggregating, affect the final privacy-utility trade-off when performed closer to the source data itself.

This research will systematically evaluate the impact of deploying these data preprocessing steps at different layers within a centralized smart meter architecture. Specifically, this work will establish a baseline scenario where raw data is processed only by the z-anonymity algorithm at the Central Entity. This baseline will then be systematically compared against variations where data preprocessing steps are first applied at the edge (on Smart Meters) or at the gateway level, allowing for a precise measurement of their impact on the final privacy-utility trade-off. By measuring the effects on data utility, information loss, and system performance, this research will provide a clear framework for understanding the trade-offs of moving computation closer to the user. All experiments will be grounded in a realistic context by using the SmartMeter Energy Consumption Data in London Households~\cite{londonSmartMeter2014} dataset. 

This thesis is structured as follows. Chapter~2 introduces the background knowledge required to understand this work. Chapter~3 reviews the related literature. Chapter~4 describes the research methodology, while Chapter~5 presents the experimental results. Chapter~6 discusses these results, and Chapter~7 concludes the thesis.